#!/usr/bin/env python3

## LICENSE: MIT

import hashlib
import importlib
import platform
import re
import shutil
import sys, os, json, logging, subprocess
import time
import urllib.parse
from datetime import datetime, timezone
from pathlib import Path
from traceback import print_tb

from click import Command, command, Option

logging.basicConfig(level=logging.INFO)

try:
    from _manager_lib import *
except ModuleNotFoundError as e:
    logging.error(f"Exception importing _manager_lib: ModuleNotFoundError: {e}")
    logging.error("Try running `pip install -r _manager_lib/requirements.txt`")
    sys.exit(1)

tracker = StateTracker()
state = tracker.read()

from attrdict import AttrDict, AttrDefault
from colorama import init, Fore, Back, Style
init()

from blessed import Terminal
from dotenv import load_dotenv, dotenv_values
import dotenv
import cfn_tools

from time import sleep
from contextlib import suppress
from collections import defaultdict

from botocore.exceptions import ClientError
import boto3
from boto3.s3.transfer import S3Transfer

import click

def get_env(name, default):
    return os.environ.get(name, default)

S3_DEV_BUCKET = get_env("S3_DEV_BUCKET", "flux-public-assets")
STACK_TMPL = "./stack/flux-securevote-voting-stack.yaml"

TEST_STACK_NAME = "sv-testnet-stack"
TEST_SUBDOMAIN = get_env("TEST_SUBDOMAIN", "tnalpha2")
TEST_NAMEPREFIX = "sv-testnet"
OFFSET = ""

VOTING_DOMAIN = get_env("VOTING_DOMAIN", "flux.vote")
MAXS_SSH_KEY = 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDCr1lcY0jTSmCARinvFJHelYGx2p+Ky0YxskSVj53ywYaLRN96w8WdN7rpCCosDQbd9KzvmKbBHHAlL8noEtARmxP4tKRvGGRyKawLLPm530CJRv4bSz03Iw2kz2V2fUWjA/RO2gNK9DCXTdDM67avv8oB/QvSobm1rSNKj6CcjTTJuQxGhJcXKrU/BZwugMIM3ELByyD6w8Jizm12JWGVgJTEIkgqgaNhmek2OLsw8+1hIC9EfhQunH9izzhEd2HoGYf3IJXlESnuRyhb7uOvOPysQDL8Hrt/Po6Wi3Lhlczy7q6wrlGQwO5/ORAfpYXGuk1lc3mTI/srgSgc38Vt'


def set_offset(offset):
    global TEST_STACK_NAME, TEST_NAMEPREFIX, TEST_SUBDOMAIN, OFFSET
    TEST_STACK_NAME += f'-{offset}'
    TEST_SUBDOMAIN += f'-{offset}'
    TEST_NAMEPREFIX += f'-{offset}'
    OFFSET = offset


cfn = None
SILENT = False


def echo(*args, sep: str = " ", **kwargs):
    if not SILENT:
        click.echo(sep.join(args), **kwargs)


def must_run(cmd, silent=False):
    logging.info("Running `%s`" % cmd)
    out = subprocess.STDOUT
    err = None
    if silent:
        out = subprocess.DEVNULL
        err = out
    if type(cmd) is list:
        to_run = cmd
    elif type(cmd) is str:
        to_run = cmd.split(' ')
    else:
        raise Exception("must_run only accepts str or list")
    exit_code = subprocess.check_call(to_run, stdout=out, stderr=err)
    logging.debug("Command `%s` exited w code %d" % (cmd, exit_code))
    if exit_code != 0:
        logging.error("Failed to run %s" % cmd)
        raise Exception("Failed to run required cmd: %s" % cmd)


class CmdRunner:
    def __init__(self, cmd_runner=must_run):
        self.cmds = []
        self.cmd_runner = cmd_runner

    def add(self, name, cmd):
        self.cmds.append((name, cmd))

    def run(self, cmd_runner=None):
        cmd_runner = self.cmd_runner if cmd_runner is None else cmd_runner
        for (n, cmd) in self.cmds:
            logging.info("Running ({name}) as cmd:\n\t{cmd}\n".format(name=n, cmd=cmd))
            cmd_runner(cmd)


def print_output(msg):
    print("\n### RESULT ###\n\n{}".format(msg))


#
# CFN STACKS
#


def get_stack(stack_name):
    ss = list(filter(lambda s: s['StackName'] == stack_name, cfn.list_stacks()['StackSummaries']))
    if len(ss) > 0:
        return ss[0]
    return None


def get_stack_details(stack_name):
    ss = list(filter(lambda s: s['StackName'] == stack_name, cfn.describe_stacks(StackName=stack_name)['Stacks']))
    return None if len(ss) == 0 else ss[0]


def get_stack_resource(stack_name, logical_resource_name):
    return cfn.describe_stack_resource(StackName=stack_name, LogicalResourceId=logical_resource_name)['StackResourceDetail']


def is_in_prog(stack_name):
    s = get_stack(stack_name)
    return s and 'IN_PROGRESS' in s['StackStatus']


def stack_exists(stack_name):
    s = get_stack(stack_name)
    return s and s['StackStatus'] != 'DELETE_COMPLETE'


def stack_failed(stack_name):
    s = get_stack(stack_name)
    return s and ('FAILED' in s['StackStatus'] or 'ROLLBACK' in s['StackStatus'])


def await_in_prog(stack_name, heading_prefix="AWAITING", fullscreen=True):
    if is_in_prog(stack_name):
        logging.info("Waiting for CFN deploy to complete before we trigger another.")
        stream_cfn_events(stack_name, heading_prefix=heading_prefix, fullscreen=fullscreen)
        logging.info("Previous deploy completed, performing deploy...")


def delete_stack(stack_name):
    r = cfn.delete_stack(StackName=stack_name)
    while stack_exists(stack_name):
        time.sleep(0.1)
    return r


def stack_del_if_necessary(stack_name):
    if stack_exists(stack_name) and get_stack(stack_name)['StackStatus'] == 'ROLLBACK_COMPLETE':
        logging.warning("Deleting {} as it's in ROLLBACK_COMPLETE".format(stack_name))
        delete_stack(stack_name)


def create_stack(stack_name, obj_url, params_aws):
    extra = {} if params_aws is None else {'Parameters': params_aws}
    r = cfn.create_stack(
        StackName=stack_name,
        TemplateURL=obj_url,
        Capabilities=['CAPABILITY_NAMED_IAM', 'CAPABILITY_AUTO_EXPAND'],
        OnFailure="DELETE",
        TimeoutInMinutes=20,
        **extra
    )
    return r['StackId']


def update_stack(stack_name, obj_url, params_aws):
    extra = {} if params_aws is None else {'Parameters': params_aws}
    r = cfn.update_stack(
        StackName=stack_name,
        TemplateURL=obj_url,
        Capabilities=['CAPABILITY_NAMED_IAM', 'CAPABILITY_AUTO_EXPAND'],
        **extra
    )
    return r['StackId']


def create_or_update_stack(stack_name, obj_url, params):
    if stack_exists(stack_name):
        return update_stack(stack_name, obj_url, params)
    else:
        return create_stack(stack_name, obj_url, params)


def get_failed_msgs(stack_name):
    evts_after = get_stack(stack_name).get('LastUpdatedTime', None)

    try:
        evts = cfn.describe_stack_events(StackName=stack_name)['StackEvents']
    except:
        logging.warning("***** Failed to get stack events! *****")
        return []
    evts_notable = list(
        filter(lambda evt:
               ('FAILED' in evt['ResourceStatus'] or 'ROLLBACK_IN_PROGRESS' in evt['ResourceStatus']) and
               (evts_after is None or evt['Timestamp'] > evts_after), evts))
    evts_w_dupes = list([(evt['LogicalResourceId'], evt.get('ResourceStatusReason', evt)) for evt in evts_notable])
    resources_done = set()
    evts_final = []
    for (r_id, reason) in evts_w_dupes:
        if r_id not in resources_done:
            evts_final.append((r_id, reason))
            resources_done.add(r_id)
    return evts_final


def cfn_outputs_to_dict(outputs):
    return {d['OutputKey']: d['OutputValue'] for d in outputs}


def _cfn_stack_extract_resources_status(stack_name, recursive=False, update_start: datetime = None, parent=None, max_old=5):
    try:
        evts = cfn.describe_stack_events(StackName=stack_name)['StackEvents']
    except ClientError as e:
        if "does not exist" in str(e):
            return {}, [], update_start
        elif "(Throttling)" in str(e):
            sleep(0.3)
            return _cfn_stack_extract_resources_status(stack_name=stack_name, recursive=recursive,
                                                       update_start=update_start, parent=parent)
        else:
            raise e
    resources = AttrDict()
    _res_ord = []
    root = None

    # find update_start first
    if update_start is None:
        for evt in evts:
            r_name = evt['LogicalResourceId']
            is_update_create_complete = evt['ResourceStatus'] in ['UPDATE_IN_PROGRESS', 'CREATE_IN_PROGRESS',
                                                                  'UPDATE_COMPLETE', 'CREATE_COMPLETE']
            if update_start is None and r_name == stack_name and is_update_create_complete:
                # just break when we get to this point since we don't want anything afterwards.
                update_start = evt['Timestamp']
                break

    n_old_counter = 0
    for evt in evts:
        r_name = evt['LogicalResourceId']

        if r_name in resources or r_name in _res_ord:  # resources we already track
            continue

        if r_name == stack_name:
            if parent is None and root is None:
                root = r_name
            else:
                continue
        is_root = root == r_name
        is_stack = evt['ResourceType'] == "AWS::CloudFormation::Stack"
        is_old = update_start and evt['Timestamp'] < update_start
        # t_plus_seconds = (evt['Timestamp'] - update_start).total_seconds()
        seconds_ago = (datetime.now(timezone.utc) - evt['Timestamp']).total_seconds()
        resources[r_name] = r = AttrDict({'status': evt['ResourceStatus'],
                                 'ts': colors('dim_white')("   (old)") if is_old else f"{seconds_ago:>3.0f}s ago",
                                 'reason': evt.get('ResourceStatusReason', '<MISSING>'),
                                 'type': evt.get('ResourceType', ""),
                                 # we always want to show stacks, so they're never "old"
                                 'is_old': is_old,
                                 'parent': parent or "<Root>",
                                 'evt': evt,
                                 'depth': 0 if is_root else 1
                                 })
        # n_old = len(list(filter(lambda k: resources[k]['is_old'] and resources[k]['parent'] == stack_name, resources)))
        if is_stack or not r['is_old'] or n_old_counter < max_old:
            _res_ord.insert(0, r_name)
            n_old_counter += 1 if r['is_old'] and not is_stack else 0
        if recursive and is_stack and r_name != stack_name:
            phys_id = evt['PhysicalResourceId']
            if phys_id != "":
                sub_name = phys_id.split('/')[1]
                sub_res, sub_res_ord, _meh = _cfn_stack_extract_resources_status(
                    sub_name, recursive=recursive, update_start=update_start, parent=stack_name
                )
                _res_ord = [f"{r_name}/{n}" for n in sub_res_ord] + _res_ord
                resources.update({f"{r_name}/{k}": AttrDict(v, depth=v['depth'] + 1) for k, v in sub_res.items()})

    root_list_maybe = [] if root is None else [root]
    used = set(root_list_maybe)
    res_ord = [r for r in _res_ord if r not in used and (used.add(r) or True)] + root_list_maybe

    return resources, res_ord, update_start


def get_c(cs, name: str) -> str:
    ns = name.split('_')
    color = ns[-1].upper()
    return (Style.DIM if 'dim' in ns else '') \
           + (Style.BRIGHT if 'l' in ns else '') \
           + cs.__getattribute__(ns[-1].upper()) if color else ''


def colors(fore='reset', back='reset', prefix='', suffix=''):
    def mk_colorful(msg):
        return f"{get_c(Fore, fore)}{get_c(Back, back)}{prefix}{msg}{suffix}{Fore.RESET}{Back.RESET}{Style.RESET_ALL}"
    return mk_colorful


def fmt_type(_r):
    tys = _r['type'].split('::')[1:]
    abbreviations = {
        'CloudFormation': 'CFN',
        'ApiGateway': 'ApiG',
        'Route53': 'R53'
    }
    return '::'.join([abbreviations.get(tys[0], tys[0])] + tys[1:])


def fmt_r(r, _r):
    rs = r.split('/')
    rs[-1] = colors('l_blue')(rs[-1])
    status_colors = {
        "DELETE_FAILED": colors('black', 'red'),
        "DELETE_IN_PROGRESS": colors('red', 'black'),
        "DELETE_COMPLETE": colors('l_red', 'black'),

        "CREATE_FAILED": colors('red'),
        "CREATE_IN_PROGRESS": colors('l_green'),
        "CREATE_COMPLETE": colors('dim_green'),

        "UPDATE_FAILED": colors('red'),
        "UPDATE_IN_PROGRESS": colors('l_green'),
        "UPDATE_COMPLETE": colors('dim_green'),

        "CLEANUP": colors('l_cyan'),
        "IS_OLD": colors('dim_white'),
    }
    s = _r['status']
    color_key = "IS_OLD" if _r['is_old'] else "CLEANUP" if "CLEANUP_IN_PROG" in s else s
    status = status_colors.get(color_key, colors())(_r['status'])
    return f"{status} - {'/'.join(rs)}"


def stream_cfn_events(stack_name, heading_prefix=None, skip_old=False, fullscreen=True):
    # echo(json.dumps(_cfn_stack_extract_resources_status(stack_name, recursive=True), indent=2))
    # return
    import curses

    _e = None

    term = Terminal()

    def clear_term():
        if fullscreen:
            print(term.clear())

    clear_term()

    def _run():
        nonlocal _e
        ansi_escape = re.compile(r'\x1B[@-_][0-?]*[ -/]*[@-~]')

        def true_len(msg: str):
            return len(ansi_escape.sub('', msg))

        def addstr(y, x, msg):
            if fullscreen:
                with term.location(x, y):
                    print(msg)
            else:
                print((x, y), msg)

        def gen_heading(update_start: datetime = None):
            dt = update_start or datetime.utcnow()
            heading = f'CFN Status ({stack_name})'
            if heading_prefix:
                heading = f'[{heading_prefix}] {heading}'
            return f'{dt.strftime("%H:%M:%S")} {heading}'

        def gen_progress_rotate(i):
            return {0: "|", 1: "/", 2: "—", 3: "\\"}[i % 4]

        addstr(0, 0, gen_heading())
        loop_counter = 0

        try:
            while is_in_prog(stack_name):
                loop_counter += 1
                try:
                    resources, _resources_order, _update_start = _cfn_stack_extract_resources_status(stack_name, recursive=True)
                except ClientError as e:
                    if 'does not exist' in str(e):
                        echo(f"ClientError: {str(e)}")
                        break
                    raise e
                clear_term()
                stdscr_height, stdscr_width = term.height, term.width
                addstr(0, 0, gen_heading(_update_start)) # + f" | update started: {_update_start.strftime('%H:%M:%S')}")
                l_num = 1
                # max_depth = max([s.count('/') for s in _resources_order])
                # last_depth = 0
                _rs_ord = _resources_order[::-1]
                _rs_with_neighbours = list(zip([None] + _rs_ord, _rs_ord, _rs_ord[1:] + [None]))
                for (prev_r, r, next_r) in _rs_with_neighbours:
                    resources[r]['next'] = resources[next_r] if next_r else None
                    resources[r]['prev'] = resources[prev_r] if prev_r else None

                # addstr(l_num, 0, f"{_rs_with_neighbours}")
                # l_num += 1
                for (prev_r, r, next_r) in _rs_with_neighbours:
                    if r not in resources:
                        addstr(l_num, 0, colors('red')(f"Not found: {r}"))
                        l_num += 1
                    else:
                        if l_num > stdscr_height - 2:
                            break

                        _r = resources[r]

                        if _r['is_old'] and skip_old:
                            continue

                        depth = _r['depth']
                        next_depth = _r.next['depth'] if _r.next else 0
                        prev_depth = _r.prev['depth'] if _r.prev else 0

                        start_char = "├" if prev_depth <= depth == next_depth or prev_depth > depth \
                            else "└" if next_depth == 0 \
                            else "└" if next_depth > depth \
                            else "└" if next_depth < depth \
                            else "┬"
                        end_char = "─" if "::Stack" not in _r['type'] \
                            else "┬" if prev_depth < depth \
                            else "├" if prev_depth == depth \
                            else "┬" if prev_depth > depth \
                            else "x"
                        # end_char = ("┬" if depth > 0 else "├") if "::Stack" in _r['type'] else " "
                        prefix = " " if _r['is_old'] else \
                            (gen_progress_rotate(loop_counter) if "IN_PROGRESS" in _r['status'] else "✔")
                        prefix += ("┆ " if depth > 1 else "") + "  " * (depth-2) + (f"{start_char}─" if depth > 0 else "")
                        prefix += end_char
                        # prefix += colors('red')(f"[{rs_left:>2d}]")

                        the_str = f"{_r['ts']} {prefix}─ {fmt_r(r, _r)}"
                        type_msg = fmt_type(_r)
                        total_len = true_len(the_str + type_msg) + 2
                        if total_len <= stdscr_width:
                            the_str = the_str + ' ' + colors('dim_cyan')("." * (stdscr_width - total_len))
                        else:
                            max_len = (stdscr_width - 2 - true_len(type_msg))
                            the_str = filter(lambda s: true_len(s) <= max_len, [the_str[:i] for i in range(len(the_str))][::-1]).__next__()
                            the_str += "…" + Fore.RESET + Back.RESET + Style.RESET_ALL
                        the_str += ' ' + colors('cyan')(fmt_type(_r))
                        addstr(l_num, 0, the_str)  # [:max_str_len]
                        if "FAILED" in _r['status']:
                            l_num += 1
                            addstr(l_num, 0, f"         {prefix} --> {_r['reason']}")  # [:max_str_len]
                        last_depth = depth
                        l_num += 1
                while l_num < stdscr_height - 1:
                    addstr(l_num, 0, " ")
                    l_num += 1
                time.sleep(2)

            addstr(1, 0, f"----------- STACK ({stack_name}) COMPLETED! ----------- In Progress: {is_in_prog(stack_name)}")
            time.sleep(1.5)
        except Exception as e:
            logging.error(f"Error in CFN stream: {e}, {repr(e)}")
            sys.stderr.write(f"Error in CFN stream: {e}, {repr(e)}\n")
            print_tb(e.__traceback__)
            with open('__tmp_manage_log', 'a') as f:
                f.write(f"Exception ({e}) at {time.time()} while streaming CFN events")
                f.write('\n\n'.join([str(time.time()), str(e), repr(e), '']))
            _e = e
            raise e

    if fullscreen:
        with term.fullscreen():
            _run()
        clear_term()
    else:
        _run()

    if _e is not None:
        echo(f"Error in stream events: {_e}, {repr(_e)}")
        sys.stderr.write(f"Error in stream events: {_e}, {repr(_e)}")


cached_s3 = None


def get_s3_and_tfer():
    global cached_s3
    if cached_s3 is None:
        cached_s3 = boto3.client('s3')
    s3_tfer = S3Transfer(cached_s3)
    return cached_s3, s3_tfer


def s3_upload(obj_key, public_read=True, bucket_name=S3_DEV_BUCKET, filepath: str = None, binary_data: bytes = None):
    s3, s3_tfer = get_s3_and_tfer()
    extra_args = {'ACL': 'public-read'} if public_read else {}
    if filepath and binary_data:
        raise Exception('cannot upload both a file and raw bytes - pick one')
    if filepath:
        s3_tfer.upload_file(filepath, bucket_name, obj_key, extra_args=extra_args)
    elif binary_data:
        s3.put_object(
            Body=binary_data,
            Bucket=bucket_name,
            ContentMD5=hashlib.md5(binary_data).hexdigest(),
            Key=obj_key,
            **({'ACL': 'public-read'} if public_read else {})
        )
    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, bucket_name, obj_key)
    return obj_url


def dict_to_cfn_params(params):
    return [{'ParameterKey': k, 'ParameterValue': v} for k, v in params.items()]


def is_wsl():
    return os.path.exists('/bin/wslpath')


def docker_lambda(cmd, extra_args=''):
    wsl = is_wsl()
    if wsl:
        print("Detected WSL...")
    mnt_dir = '$PWD' if not wsl else '$(wslpath -w $PWD)'
    # sts = boto3.client('sts')
    # session_token = sts.get_session_token(DurationSeconds=900)['Credentials']
    # env_args = ' '.join([f"-e {k}={v}" for k,v in {
    #     'AWS_ACCESS_KEY_ID': session_token['AccessKeyId'],
    #     'AWS_SESSION_TOKEN': session_token['SessionToken'],
    #     'AWS_SECRET_ACCESS_KEY': session_token['SecretAccessKey'],
    # }.items()])
    env_args = ''
    return os.system(f'docker run --rm -t -v "{mnt_dir}":/var/task {env_args} {extra_args} lambci/lambda:build-python3.6 {cmd}')


@click.group()
@click.option("--debug/--no-debug", default=False)
@click.option("--offset", "-o", default="", type=click.STRING, help="use an offset for names to avoid conflicts.")
@click.option("--region", default="", type=click.STRING, help="specify an AWS region if need be")
def cli(debug, offset, region):
    global cfn
    if debug:
        logging.basicConfig(level=logging.DEBUG)
        logging.debug("Debug mode enabled")
    if offset:
        set_offset(offset)
    cfn_extras = {} if region == '' else {'region_name': region}
    cfn = boto3.client('cloudformation', **cfn_extras)


py_targets_raw = ["cr", "members"]
py_targets = click.Choice(py_targets_raw + ['all'])


@cli.command(name='pip')
@click.argument('target', default="all", type=py_targets) #, help="The target python app to install deps for; with 'all' being all targets")
@click.argument('pkgs', nargs=-1)
@click.option('--no-system', type=click.BOOL, is_flag=True, default=False,
              help="do not include --system in pip install args")
@click.option('--pip-args', type=click.STRING, default='', help="extra args to pass to pip3 install")
@click.option('--use-docker', type=click.BOOL, is_flag=True, default=False,
              help="use the lambda-build docker container to install dependencies (required on MacOS and Windows")
def pip(target, pkgs, no_system, pip_args, use_docker):
    targets = py_targets_raw if target == "all" else [target]
    _pkgs = list(pkgs)
    target_paths = [{'cr': 'stack/cr/common', 'members': 'stack/app/members'}[target] for target in targets]
    for target_path in target_paths:
        _pip(target_path, _pkgs, no_system, pip_args, use_docker)


def _pip(target_path, pkgs, no_system, pip_args, use_docker):
    curr_dir = os.getcwd()
    if os.path.exists(target_path):
        reqs_file = 'requirements.txt'
        os.chdir(target_path)
        try:
            with open(reqs_file, 'r') as f:
                reqs_old = f.read().split('\n')
        except FileNotFoundError as e:
            reqs_old = []
        reqs = list(reqs_old)
        for pkg in pkgs:
            if pkg in reqs_old:
                continue
            reqs.append(pkg)
        print('New requirements file lines:', reqs)
        with open(reqs_file, 'w+') as f:
            f.write('\n'.join(reqs))
        print('Platform:', platform.system())
        system = '' if no_system else '--system'
        _cmd_outer = '{}'
        if platform.system() == "Darwin":
            _cmd_outer = 'docker run --rm -v "$PWD":/var/task lambci/lambda:build-python3.6 {}'
            system = ''
        # _cmd = _cmd_outer.format(...origcmd here...)
        pip_cmd = f'pip3 install --target=deps -r {reqs_file} --upgrade {pip_args}'
        # _ec = docker_lambda(pip_cmd)
        _ec = os.system(pip_cmd)

        if _ec != 0:
           raise Exception("Failed to install packages")
        print_output(f"Installed packages {pkgs} / {reqs} to {target_path}")
    else:
        raise Exception("Target of {} is unknown".format(target_path))
    os.chdir(curr_dir)


@cli.command(name='test-chaincode')
def test_chaincode():
    test_cmd = 'bash -c "cd stack/cr/chaincode; ls -al && tail cfnwrapper.py && tail lib.py; python3 test/test_mk_contract.py"'
    docker_lambda(test_cmd)


@cli.command(name="stream-cfn")
@click.argument('stack-name', type=click.STRING, default='')
def cmd_stream_cfn(stack_name):
    if stack_name == '':
        stack_name = TEST_STACK_NAME
    stream_cfn_events(stack_name)


@cli.command(name='upload-func')
@click.argument('func-path')
@click.argument('func-name')
def upload_func(func_path, func_name):
    if func_path[-3:] != ".py":
        logging.error("Must target a python file to upload (whole dir gets uploaded tho)")
        sys.exit(1)
    root_dir = os.path.dirname(os.path.realpath(__file__))
    dir_path = os.path.dirname(func_path)
    os.chdir(dir_path)
    if os.path.exists(f"{root_dir}/tmp-func.zip"):
        must_run(f'rm -v {root_dir}/tmp-func.zip', silent=True)
    must_run(f'zip -r {root_dir}/tmp-func.zip ./', silent=True)
    os.chdir(root_dir)
    with open('./tmp-func.zip', 'rb') as f:
        zip_bytes = f.read()
    # obj_key = f'./tmp-func-{int(time.time())}.zip'
    # obj_url = s3_upload(obj_key, filepath=hashlib.sha256(zip_bytes).hexdigest() + ".zip")

    awslam = boto3.client('lambda')
    awslam.update_function_code(FunctionName=func_name, ZipFile=zip_bytes, Publish=True)

    print_output(f"Updated function {func_name}")


@cli.command(name='deploy-ns')
@click.argument('stack-path')
@click.argument('stack-name')
@click.option('--params', default='',
              help="(JSON Dict) Parameters to use. Default will use '{\"pOffset\": \"<value provided via --offset>\"}'")
def deploy_nestedstack(stack_path, stack_name, params):
    TMP_TMPL_FILE = "./tmp-nestedstack-dev.yaml"
    pkg_cmd = f"aws cloudformation package --template-file {stack_path} --s3-bucket {S3_DEV_BUCKET} --output-template-file {TMP_TMPL_FILE}"
    must_run(pkg_cmd, silent=True)

    filename = os.path.basename(stack_path)
    obj_key = f'./ns-dev/tmp-{int(time.time())}-{filename}'
    obj_url = s3_upload(obj_key, filepath=TMP_TMPL_FILE)

    if not params:
        prev_params = cfn.describe_stacks(StackName=stack_name)['Stacks'][0]['Parameters']
        cfn_params = [{'ParameterKey': p['ParameterKey'], 'UsePreviousValue': True} for p in prev_params]
        print(f"Using params: {json.dumps(cfn_params)}")
    else:
        json_params = json.loads(params)
        if type(json_params) is list:
            cfn_params = json_params
        else:
            cfn_params = dict_to_cfn_params(json_params if params else {'pOffset': OFFSET})
    sid = create_or_update_stack(stack_name, obj_url, cfn_params)
    logging.info(f"Stack SID: {sid}")

    stream_cfn_events(stack_name, heading_prefix="DEPLOY-NS-DEV")
    print_output(f"Stack deploy/create/update run for {stack_name} w sid: {sid}")

    if stack_failed(stack_name):
        msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
        print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))


@cli.command(name='deploy-macros')
@click.argument('stack-name', default='sv-macros')
def deploy_macros(stack_name):
    TMP_TMPL_FILE = "tmp-macros.yaml"

    pkg_cmd = f"aws cloudformation package --template-file ./stack/sv-macros.yaml --s3-bucket {S3_DEV_BUCKET} --output-template-file {TMP_TMPL_FILE}"
    print("Package:", pkg_cmd)
    must_run(pkg_cmd, silent=True)

    obj_key = "sv-macros.yaml"
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)
    s3_tfer.upload_file(TMP_TMPL_FILE, S3_DEV_BUCKET, obj_key, extra_args={'ACL': 'public-read'})
    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, S3_DEV_BUCKET, obj_key)

    params_aws = []

    if stack_exists(stack_name):
        sid = update_stack(stack_name, obj_url, params_aws)
    else:
        sid = create_stack(stack_name, obj_url, params_aws)

    stream_cfn_events(stack_name, heading_prefix="DEPLOY")


@cli.command(name='destroy')
@click.argument('stack-name', type=click.STRING, default='')
@click.option("--watch", default=False, type=click.BOOL, is_flag=True, help="Stream CFN events as it deploys.")
@click.pass_context
def destroy(ctx, watch, stack_name):
    if stack_name == '':
        stack_name = TEST_STACK_NAME

    if watch:
        stream_cfn_events(stack_name, heading_prefix="AWAIT")

    del_resp = cfn.delete_stack(StackName=stack_name)
    print(f"Del response: {del_resp}")

    if watch:
        stream_cfn_events(stack_name, heading_prefix="DELETE")

    print_output(f"Deleted: {del_resp}")


def _step_to_parameters(step: int):
    steps = [ {'pCreateNodes': 'false'}, {'pCreateChaincodeStack': 'false'}, {'pCreateMembersApp': 'false'}, {} ]
    return steps[step]


@cli.command(name='deploy')
@click.argument('stack-name', type=click.STRING, default='')
@click.option("--deploy/--no-deploy", default=True, is_flag=True)
@click.option("--open-browser/--no-open-browser", default=False, is_flag=True)
@click.option("--del-packaged-tmpl/--no-del-packaged-tmpl", default=True, is_flag=True,
              help="Remove tmp-stack.yaml after we're done generating + uploading it")
@click.option("--watch", default=False, type=click.BOOL, is_flag=True, help="Stream CFN events as it deploys.")
@click.option("--ssh-key", default=MAXS_SSH_KEY, type=click.STRING,
              help="the ssh key with which to configure EC2 nodes.")
@click.option("--use-existing", default=False, is_flag=True, type=click.BOOL,
              help="use tmp-stack.yaml if it exists instead of running aws cfn package")
@click.option("--use-last-uploaded", default=False, is_flag=True, type=click.BOOL,
              help="do not package a new template, just redeploy the last one uploaded to S3.")
@click.option("--step", default=3, type=click.IntRange(0, 3), help="Proceed only to step N of the stack deployment. The stack will _progressively_ deploy more and more resources as you increase step. The default is to deploy everything.")
@click.pass_context
def deploy(ctx, stack_name, deploy, open_browser, del_packaged_tmpl, watch, ssh_key, use_existing,
                use_last_uploaded, step):

    raise Exception('deprecated')

    if stack_name == '':
        stack_name = TEST_STACK_NAME

    if deploy:
        await_in_prog(stack_name)

    TMP_TMPL_FILE = 'tmp-stack.yaml'
    obj_key = "templates/" + STACK_TMPL.split('/')[-1]
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)

    if not use_last_uploaded:
        if os.path.exists(TMP_TMPL_FILE) and use_existing:
            print(f"{TMP_TMPL_FILE} exists - skipping `aws cloudformation package`; "
                  f"use --disable-use-existing to disable this and rm the old tmp file.")
        else:
            must_run("aws cloudformation package --template-file {} --s3-bucket {} --output-template-file {}"
                     .format(STACK_TMPL, S3_DEV_BUCKET, TMP_TMPL_FILE), silent=True)
        # upload tmp file regardless
        s3_tfer.upload_file(TMP_TMPL_FILE, S3_DEV_BUCKET, obj_key, extra_args={'ACL': 'public-read'})

    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, S3_DEV_BUCKET, obj_key)
    print(f"Template URL: {obj_url}")

    params = {
        'NamePrefix': TEST_NAMEPREFIX,
        # 'HostedZone': 'Z2NVOFJHPZ9S2O',
        'HostedZoneDomain': VOTING_DOMAIN,
        'EC2InstanceType': 't2.small',
        'NumberOfEthereumConsensusNodes': '1',
        'NumberOfEthereumPublicNodes': '1',
        'Subdomain': TEST_SUBDOMAIN,
        'SSHKey': ssh_key,
        'AdminEmail': 'test-stack-flux-vote@xk.io',
        'pDeployMacros': 'false',
        # 'pDeployAcmAutovalidate': 'false',
        # 'Nonce': str(int(time.time()))
    }
    params.update(**_step_to_parameters(step))
    params_aws = dict_to_cfn_params(params)

    cfn_console_create_url = "https://console.aws.amazon.com/cloudformation/home?region={region}#/stacks/new?stackName={stack_name}&templateURL={tmpl_url}".format(
        obj_url, region=s3.meta.region_name, stack_name=stack_name, tmpl_url=urllib.parse.quote(obj_url, safe=''))

    def gen_cfn_evt_url(sid):
        return "https://ap-southeast-2.console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/{}/events".format(
            urllib.parse.quote(sid, safe=''))

    def gen_open_url_cmd(url):
        return "cmd.exe /c start {}".format(url)

    if deploy:
        await_in_prog(stack_name)
        stack_del_if_necessary(stack_name)
        if stack_exists(stack_name):
            sid = update_stack(stack_name, obj_url, params_aws)
        else:
            sid = create_stack(stack_name, obj_url, params_aws)
        cfn_evt_url = gen_cfn_evt_url(sid)
        if open_browser:
            os.system(gen_open_url_cmd(cfn_evt_url))
        if watch:
            stream_cfn_events(stack_name, heading_prefix="DEPLOY")
            _exists = stack_exists(stack_name)
            if not _exists or stack_failed(stack_name):
                if _exists:
                    msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
                    print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))
                else:
                    print_output("Deploy failed and is deleted.")
            else:
                print_output("Deploy Success! {}".format(cfn_evt_url))
                if del_packaged_tmpl:
                    os.system("rm {}".format(TMP_TMPL_FILE))
                deets = get_stack_details(stack_name)

                print_output(f"Outputs: {json.dumps(cfn_outputs_to_dict(deets['Outputs']), indent=2)}")
        else:
            print_output("Initiated deploy of {}\n\nLink: {}".format(sid, cfn_evt_url))
            if del_packaged_tmpl:
                os.system("rm {}".format(TMP_TMPL_FILE))

    else:
        if open_browser:
            _to_run = gen_open_url_cmd(cfn_console_create_url)
            print("Opening CFN template via console. CMD: {}".format(_to_run))
            os.system(_to_run)
        print_output("""Uploaded {}
        Launch via CloudFormation: {}""".format(obj_url, cfn_console_create_url))


def get_ns_details(sn, r_name):
    for r in state.get_stack_resources(sn):
        if not (r['LogicalResourceId'] == r_name and r['ResourceType'] == "AWS::CloudFormation::Stack"):
            break
        ns_arn = r['PhysicalResourceId']
    else:
        raise Exception(f"Cannot find nested stack with name {r_name} in main stack {sn}")
    with open(STACK_TMPL, 'r') as f:
        contents = f.read()
        results = re.search(f"{r_name}:[\n\s]*Type: AWS::CloudFormation::Stack[\n\s\w:]*TemplateURL:(.*)\.yaml", contents, re.M | re.S)
        ns_file_path = results.group(1) + ".yaml"
    return { 'arn': ns_arn, 'file_path': os.path.join('./stack', ns_file_path) }


def default_params_from_env(env_name, evs):
    params = {
        'NamePrefix': evs.NAME_PREFIX,
        'EnvironmentName': env_name,
        'HostedZoneDomain': evs.DOMAIN,
        'EC2InstanceType': 't2.small' if env_name != 'prod' else 't3.medium',
        'NumberOfEthereumConsensusNodes': '2',
        'NumberOfEthereumPublicNodes': '2',
        'Subdomain': evs.SUBDOMAIN,
        'AdminEmail': evs.get('EMAIL_FROM_ADDR', 'test-stack-flux-vote@xk.io'),
        'pDeployMacros': 'false',
        'pCreateAlb': 'true',
        'pVoterGroupToAddressMapJson': json.dumps(voter_group_to_scs[env_name]),
        'pMemberEmailDeliveryNotificationEmail': evs.get('NOTIFICATION_EMAIL'),
        'pHashSalt': evs.get('PRIV_FAILING_EMAIL_SALT', os.urandom(10).hex()),
        # 'pDeployAcmAutovalidate': 'false',
        # 'Nonce': str(int(time.time()))
    }
    params.update({ 'SSHKey': evs.get("SSH_KEY", MAXS_SSH_KEY)})  #  if env_name != "prod" else ''

    return params


def gen_packaged_stack_tmp_filename(env_name):
    return f'tmp-stack.{env_name}.yaml'


def get_evs(env_name, do_load=True):
    env_file = f'.env.{env_name}'
    if os.path.exists(env_file):
        if do_load:
            load_dotenv(env_file, override=True)
        evs = AttrDict(dotenv_values(env_file))
        priv_evs = get_evs(f'{env_name}.priv', do_load=do_load)
        return AttrDict(**evs, **priv_evs)
    return AttrDict()


def get_env_name(env_name: str):
    return env_name if not env_name.startswith(".env.") else env_name[5:]


@cli.command(name='watch-env')
@click.argument('env-name', type=click.STRING, default='dev')
@click.option("--no-fullscreen", default=False, is_flag=True)
def watch_env(env_name, no_fullscreen):
    env_name = get_env_name(env_name)
    evs = get_evs(env_name)
    stack_name = evs.STACK_NAME
    await_in_prog(stack_name, fullscreen=not no_fullscreen)


@cli.command(name='sync-env')
@click.argument('env-name', type=click.STRING, default='dev')
@click.option("--nested-stack", "-ns", type=click.STRING, help="The resource name of the nested stack to update")
@click.option("--watch/--no-watch", default=True, is_flag=True, help="Stream CFN events as it deploys.")
@click.option("--set-params", type=click.STRING, help="JSON encoded parameters. New values will be set these params, and existing values will be removed from the cache.")
@click.option("--update-params", type=click.STRING, help="JSON encoded parameters. New values will be set _only_ on these params, and existing values will be used for existing params.")
@click.option("--pkg-python/--no-pkg-python", default=True)
@click.option("--use-last-uploaded", default=False, is_flag=True,
              help="do not package a new template, just redeploy the last one uploaded to S3.")
@click.option("--no-fullscreen", default=False, is_flag=True)
@click.pass_context
def sync_env(ctx, env_name, nested_stack, watch, set_params, update_params, pkg_python, use_last_uploaded, no_fullscreen):
    if set_params and update_params:
        raise Exception("Cannot set and update params at the same time. Use one.")
    fullscreen = not no_fullscreen

    env_name = get_env_name(env_name)
    evs = get_evs(env_name)
    stack_name = evs.STACK_NAME

    if deploy:
        await_in_prog(stack_name, fullscreen=fullscreen)

    tmp_template_filename = gen_packaged_stack_tmp_filename(env_name)
    obj_key = f"templates/{env_name}" + os.path.split(evs.STACK_TEMPLATE)[-1]
    s3, s3_tfer = get_s3_and_tfer()

    if not use_last_uploaded:
        must_run("aws cloudformation package --template-file {} --s3-bucket {} --output-template-file {}"
                 .format(evs.STACK_TEMPLATE, evs.S3_CFN_SUPPORT_BUCKET, tmp_template_filename), silent=True)
        s3_tfer.upload_file(tmp_template_filename, evs.S3_CFN_SUPPORT_BUCKET, obj_key, extra_args={'ACL': 'public-read'})

    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, evs.S3_CFN_SUPPORT_BUCKET, obj_key)
    print(f"Template URL: {obj_url}")

    params = default_params_from_env(env_name, evs)
    # params.update(**_step_to_parameters(step))
    params_aws = dict_to_cfn_params(params)

    cfn_console_create_url = "https://console.aws.amazon.com/cloudformation/home?region={region}#/stacks/new?stackName={stack_name}&templateURL={tmpl_url}".format(
        obj_url, region=s3.meta.region_name, stack_name=stack_name, tmpl_url=urllib.parse.quote(obj_url, safe=''))

    print_output("""Uploaded {}
            Launch via CloudFormation: {}""".format(obj_url, cfn_console_create_url))

    def gen_cfn_evt_url(sid):
        return "https://ap-southeast-2.console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/{}/events".format(
            urllib.parse.quote(sid, safe=''))

    def gen_open_url_cmd(url):
        return "cmd.exe /c start {}".format(url)

    await_in_prog(stack_name, heading_prefix="AWAITING [UNEXPECTED]", fullscreen=fullscreen)
    stack_del_if_necessary(stack_name)
    if stack_exists(stack_name):
        sid = update_stack(stack_name, obj_url, params_aws)
    else:
        sid = create_stack(stack_name, obj_url, params_aws)
    cfn_evt_url = gen_cfn_evt_url(sid)
    if watch:
        stream_cfn_events(stack_name, heading_prefix="DEPLOY", fullscreen=fullscreen)
        _exists = stack_exists(stack_name)
        if not _exists or stack_failed(stack_name):
            if _exists:
                msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
                print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))
            else:
                print_output("Deploy failed and is deleted.")
        else:
            print_output("Deploy Success! {}".format(cfn_evt_url))
            deets = get_stack_details(stack_name)
            outputs = AttrDefault(lambda: '<< UNKNOWN OUTPUT >>', cfn_outputs_to_dict(deets['Outputs']))
            print_output(f"Outputs: {json.dumps(dict(outputs.items()), indent=2)}")
            print_output(f"""Env Vars for UI:

VUE_APP_WEB3_PROVIDER={outputs.oWeb3Provider}
VUE_APP_DEMOC_HASH={outputs.oDemocHash}
VUE_APP_INDEX_CONTRACT_ADDR={outputs.oIndexAddr}
VUE_APP_AUX_CONTRACT_ADDR={outputs.oBBFarmAux2Addr}
VUE_APP_API_ENDPOINT={outputs.oApiUrl}
VUE_APP_TOKEN_LOOKUP={outputs.oTokenAbbrLookupAddr}

""")
            try:
                os.system(f'notify-send "CFN Stack: {stack_name}"' 'Completed Deployment')
            except:
                pass
    else:
        print_output("Initiated deploy of {}\n\nLink: {}".format(sid, cfn_evt_url))


def package_lambda(resource_name: str, lambda_path: str, layers: List[Path]):
    # todo: maybe should use working directory?
    root_dir = Path(os.path.dirname(os.path.realpath(__file__)))
    tmp_zip = f"{root_dir}/tmp-func-{resource_name}.zip"

    if os.path.exists(tmp_zip):
        must_run(f'rm -v {tmp_zip}', silent=True)

    os.chdir(lambda_path)
    must_run(f'zip -r {tmp_zip} ./', silent=True)

    for layer in layers:
        os.chdir(layer.parent)
        must_run(f'zip -ur {tmp_zip} ./{layer.name}', silent=True)
    os.chdir(root_dir)
    return tmp_zip


@cli.command(name='sync-lambda')
@click.argument('env-name', type=click.STRING, default='dev')
@click.argument('resource-name')
@click.argument('nested', nargs=-1)
@click.option('--upload-layers', is_flag=True, default=False)
def sync_lambda(env_name, resource_name, nested, upload_layers=False):
    raise Exception("not working atm")
    env_name = get_env_name(env_name)
    evs = get_evs(env_name)
    root_tmpl_path = Path(evs.STACK_TEMPLATE).resolve()
    tmpls = [ (root_tmpl_path.parent, evs.STACK_NAME, cfn_tools.load_yaml(root_tmpl_path.read_text())) ]

    for ns_logical_name in nested:
        (last_path, last_name, last_stack) = tmpls[-1]
        ns_resource = last_stack['Resources'][ns_logical_name]
        path_key = ({
            "AWS::Serverless::Application": "Location",
            "AWS::CloudFormation::Stack": "TemplateURL"
        })[ns_resource['Type']]
        ns_path = last_path / Path(ns_resource['Properties'][path_key])
        ns_stack_name = get_stack_resource(last_name, ns_logical_name)['PhysicalResourceId'].split('/')[-2]
        tmpls.append((ns_path.parent, ns_stack_name, cfn_tools.load_yaml(ns_path.read_text())))

    final_tmpl_dir, final_stack_name, final_tmpl = tmpls[-1]
    lambda_func_name = get_stack_resource(final_stack_name, resource_name)['PhysicalResourceId']

    lambda_res = final_tmpl['Resources'][resource_name]['Properties']
    lambda_code_uri = lambda_res['CodeUri']
    lambda_path = final_tmpl_dir / lambda_code_uri

    print(lambda_path, lambda_code_uri, lambda_res)

    layers = [] if not upload_layers or 'Layers' not in lambda_res else [ final_tmpl_dir / final_tmpl['Resources'][l['Ref']]['Properties']['ContentUri'] for l in lambda_res['Layers'] ]
    tmp_zip = package_lambda(resource_name, lambda_path, layers)

    with open(f'./{tmp_zip}', 'rb') as f:
        zip_bytes = f.read()
    # obj_key = f'./tmp-func-{int(time.time())}.zip'
    # obj_url = s3_upload(obj_key, filepath=hashlib.sha256(zip_bytes).hexdigest() + ".zip")

    obj_key = f'sync-lambda{resource_name}.zip'
    zip_url = s3_upload(obj_key=obj_key, bucket_name=S3_DEV_BUCKET, binary_data=zip_bytes)

    awslam = boto3.client('lambda')
    resp = awslam.update_function_code(FunctionName=lambda_func_name, S3Key=obj_key,
                                       S3Bucket=evs.S3_CFN_SUPPORT_BUCKET, Publish=True)

    print_output(f"Updated function {lambda_func_name}. Resp: {resp}")


script_info = {
    'loadMembers': {
        'module': 'stack.app.members.api.scripts.loadMembers',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_load_members',
        'click_f': 'load_members'
    },
    'setupMemberClasses': {
        'module': 'stack.app.members.api.scripts.setupMemberClasses',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'append_or_set_env': {
            'PYTHONPATH': Path('stack/cr/chaincode').absolute().__str__()
        },
        'function': '_setup_member_classes',
        'click_f': 'setup_member_classes',
        'args': [('oWeb3Provider', 'cfn'), ('oErc20BalanceProxyAddr', 'cfn')]
    },
    'sendCoins': {
        'module': 'stack.app.members.api.scripts.sendCoins',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_send_coins',
        'click_f': 'send_coins',
        'args': [('oWeb3Provider', 'cfn')]
    },
    'createBallots': {
        'module': 'stack.app.members.api.scripts.createBallots',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_create_ballots',
        'click_f': 'create_ballots',
        'args': [('oWeb3Provider', 'cfn'), ('oIndexAddr', 'cfn'), ('oDemocHash', 'cfn')]
    },
    'memberRegistrationStats': {
        'module': 'stack.app.members.api.scripts.memberRegistrationStats',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_member_rego_stats',
        'click_f': 'member_rego_stats'
    },
    'setMemberVotingWeight': {
        'module': 'stack.app.members.api.scripts.memberVotingWeight',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_set_member_voting_weight',
        'click_f': 'set_member_voting_weight',
        'args': [('http_provider', 'oWeb3Provider', 'cfn')]
    },
    'getMemberVotingWeight': {
        'module': 'stack.app.members.api.scripts.memberVotingWeight',
        'env_vars': ['AWS_PROFILE', 'AWS_DEFAULT_REGION', 'NAME_PREFIX'],
        'remap_env': [('NAME_PREFIX', 'pNamePrefix')],
        'function': '_get_member_voting_weight',
        'click_f': 'get_member_voting_weight',
        'args': [('http_provider', 'oWeb3Provider', 'cfn')]
    }
}


def script_needs_env(script, var_name):
    _vars = script_info[script]['env_vars']
    return var_name in _vars or any([ev is tuple and var_name == ev[0] for ev in _vars])


@click.group('script-env')
@click.argument('env', default="dev")
@click.pass_context
def scripts(ctx, env):
    ctx.obj = dict(env=env, evs=get_evs(env, do_load=False))


cli.add_command(scripts)


# # todo: forwarding unknown options: http://click.palletsprojects.com/en/5.x/advanced/
# @scripts.command(name='run')
# @click.argument('script-name', type=click.Choice(list(script_info.keys())))
# @click.pass_context
# def run_script(ctx: click.Context, script_name):
#     env_name = get_env_name(ctx.parent.params['env'])
#     evs = get_evs(env_name, do_load=False)
#     our_script = script_info[script_name]
#     env_vars_to_load = {k: v for (k, v) in evs.items() if script_needs_env(script_name, k)}
#     for (k, v) in env_vars_to_load.items():
#         os.environ[k] = v
#     if our_script.get('remap_env', None):
#         for (oldName, newName) in our_script['remap_env']:
#             os.environ[newName] = os.environ[oldName]
#
#     script_module = importlib.import_module(our_script['module'])
#     print(dir(script_module))
#     getattr(script_module, our_script['function'])("~/sv-test-members.csv")


@click.group('run2', invoke_without_command=True)
@click.argument('script-name', type=click.Choice(list(script_info.keys())))
@click.argument('args', nargs=-1)
@click.option('--gen-args', default=False, is_flag=True)
@click.pass_context
def run_script(ctx, script_name, args, gen_args):
    env_name = get_env_name(ctx.parent.params['env'])
    evs = get_evs(env_name, do_load=False)
    our_script = script_info[script_name]

    if gen_args and 'args' not in our_script:
        raise Exception('cannot gen args for this')

    env_vars_to_load = {k: v for (k, v) in evs.items() if script_needs_env(script_name, k)}
    logging.info(env_vars_to_load)

    for (k, v) in our_script.get('append_or_set_env', {}).items():
        env_vars_to_load[k] = ':'.join(filter(lambda v: v is not None, [v, os.environ.get(k, None)]))

    for (k, v) in env_vars_to_load.items():
        os.environ[k] = v

    if our_script.get('remap_env', None):
        for (oldName, newName) in our_script['remap_env']:
            os.environ[newName] = os.environ[oldName]

    script_module = importlib.import_module(our_script['module'])

    _args = []
    if gen_args:
        stack_ds = cfn_outputs_to_dict(get_stack_details(evs.STACK_NAME)['Outputs'])
        for (name, source) in our_script['args']:
            if source == 'cfn':
                _args.append(stack_ds[name])
            else:
                raise Exception('no other sources of args supported')

    getattr(script_module, our_script['function'])(*_args, *args)


scripts.add_command(run_script)


@click.group('run')
@click.option('--gen-args', is_flag=True, default=False)
@click.pass_context
def run_dynamic(ctx, gen_args):
    ctx.obj['gen_args'] = gen_args
    evs = ctx.obj['evs']


# prep import and remove a bunch-o-modules
orig_modules = set(sys.modules.keys())


def gen_cmd(_script, _script_name, _script_params):
    script_invoke_name = _script['click_f'].lower().replace('_', '-')

    @click.command(name=script_invoke_name, context_settings=dict(allow_extra_args=True, ignore_unknown_options=True))
    @click.pass_context
    def new_cmd(ctx, **kwargs):
        logging.info(f'Running dynamically loaded command: {script_invoke_name} with args: {ctx.args} {ctx.params}')
        # logging.info(f'Script: {_script}')

        evs = ctx.obj['evs']
        gen_args = ctx.obj['gen_args']
        generated_opts = {}
        if gen_args:
            stack_ds = cfn_outputs_to_dict(get_stack_details(evs.STACK_NAME)['Outputs'])
            for (opt_name, output_name, source) in _script['args']:
                if source == 'cfn':
                    generated_opts[opt_name] = stack_ds[output_name]
                    print(f"checking {opt_name} in {ctx.params} {ctx.args}")
                    if any(filter(lambda p: p == opt_name and ctx.params[p] is None, ctx.params)):
                        ctx.params[opt_name] = generated_opts[opt_name]
                else:
                    raise Exception('no other sources of args supported')

        env_vars_to_load = {k: v for (k, v) in evs.items() if script_needs_env(_script_name, k)}
        logging.info(env_vars_to_load)

        for (k, v) in script.get('append_or_set_env', {}).items():
            env_vars_to_load[k] = ':'.join(
                filter(lambda v: v is not None, [v, os.environ.get(k, None)]))

        for (k, v) in env_vars_to_load.items():
            os.environ[k] = v

        if script.get('remap_env', None):
            for (oldName, newName) in script['remap_env']:
                os.environ[newName] = os.environ[oldName]

        # ctx.params

        logging.info(f'Running dynamically loaded command: {script_invoke_name} with args: {ctx.args} {ctx.params}')

        kwargs.update(generated_opts)

        script_module = importlib.import_module(_script['module']) # importlib.import_module(script['module'])
        ctx.invoke(getattr(script_module, _script['click_f']), **kwargs)

    generatable_opts = list([a[0] for a in _script.get('args', [])])
    print(generatable_opts)

    def mod_p(p):
        if p.name in generatable_opts:
            p.required = False
        return p

    new_cmd.params = list([mod_p(p) for p in _script_params])
    return new_cmd


dyn_modules = {}
for (script_name, script) in script_info.items():
    if 'click_f' in script:
        dyn_modules[script_name] = importlib.import_module(script['module'])
        script_params = getattr(dyn_modules[script_name], script['click_f']).params
        del dyn_modules[script_name]
        run_dynamic.add_command(gen_cmd(script, script_name, script_params))

# remove the modules we imported temporarily
next_modules = set(sys.modules.keys())
modules_diff = orig_modules ^ next_modules
for _module in modules_diff:
    del sys.modules[_module]
importlib.invalidate_caches()

scripts.add_command(run_dynamic)


@cli.command(name='outputs-env')
@click.argument('env-name', type=click.STRING, default='dev')
def outputs_env(env_name):
    env_name = get_env_name(env_name)
    evs = get_evs(env_name)
    deets = get_stack_details(evs.STACK_NAME)
    outputs = AttrDefault(lambda: '<< UNKNOWN OUTPUT >>', cfn_outputs_to_dict(deets['Outputs']))
    print_output(f"Outputs: {json.dumps(dict(outputs.items()), indent=2)}")
    print_output(f"""Env Vars for UI:

## VUE

VUE_APP_WEB3_PROVIDER={outputs.oWeb3Provider}
VUE_APP_DEMOC_HASH={outputs.oDemocHash}
VUE_APP_INDEX_CONTRACT_ADDR={outputs.oIndexAddr}
VUE_APP_AUX_CONTRACT_ADDR={outputs.oBBFarmAux2Addr}
VUE_APP_API_ENDPOINT={outputs.oApiUrl}
VUE_APP_TOKEN_LOOKUP={outputs.oTokenAbbrLookupAddr}
VUE_APP_CHAINSPEC_URL={outputs.oChainSpecUrl}

## ELM

MAIN_TITLE="Blockchain Australia AGM Resolutions and Elections{' ('+env_name+')' if env_name != 'prod' else ''}"
DEV={'true' if env_name == 'dev' else 'false'}
DEMOC_HASH={outputs.oDemocHash}
INDEX_ADDR={outputs.oIndexAddr}
AUX_CONTRACT_ADDR={outputs.oBBFarmAux2Addr}
ARCHIVE_PUSH_API_KEY=UmNrB7cifZ2N1LlnyM4RXK1xuK2VpIQaamgmlSBb
WEB3_PROVIDER={outputs.oWeb3Provider}
MEMBER_GROUPS_JSON='{json.dumps(voter_group_to_scs[env_name])}'

""")


voter_group_to_scs = {
    'dev': {"EX,SCALE,CORP": "0xD0237d3a126880Aaadfe3c83b96Ce87267B76F8d",
            "EX": "0xD6BD84320FDb4BB797f910fbb78Fda4737Fe355F", "SCALE": "0x91f64c36E3ed2728Dc3c02Dc66891DD35BCebA9C",
            "CORP": "0xbFB3fc489A4a5dEf84480A5bfc3df0a82FaA8B29",
            "FELLOW": "0xcB5993006192654b53802Eb0A308b1fFea9FEb32", "IND": "0x2F7DD97398267C51741cF123747ADbE22566BCb8",
            "STUD": "0x23F11d26028C4343C8E49487F7db3f87A752296d"},
    'prod': {"EX,SCALE,CORP": "0x012a9Db1184C054Ad933aD6A951d925a0004Df8b",
             "EX": "0x28F56525a76eF47e95b856927A29f1C21AeA463d", "SCALE": "0x99F15F49E5E88295Ef5e1aE8daCE6709cCCC01Ec",
             "CORP": "0x60F7C513eCe7AFD2BD95ffc218a8c0Ac34E989a9",
             "FELLOW": "0xf646789fCe64761008e67026c2045308751E52bc",
             "IND": "0x722871602A99c01Effafc29F88EB59d8a36Ac9FE", "STUD": "0x446bd9Ac0abFfb3F3574C2287066616A6B0a0181"}
}


# monkey patch so usage output looks nicer
sys.argv[0] = './manage'
cli()
