#!/usr/bin/env python3

## LICENSE: MIT

import hashlib
import platform
import re
import shutil
import sys, os, json, logging, subprocess
import time
import urllib.parse
from datetime import datetime, timezone
from pathlib import Path
from traceback import print_tb

logging.basicConfig(level=logging.INFO)

try:
    from _manager_lib import *
except ModuleNotFoundError as e:
    logging.error(f"Exception importing _manager_lib: ModuleNotFoundError: {e}")
    logging.error("Try running `pip install -r _manager_lib/requirements.txt`")
    sys.exit(1)

tracker = StateTracker()
state = tracker.read()

from attrdict import AttrDict
from colorama import init, Fore, Back, Style
init()

from blessed import Terminal
from dotenv import load_dotenv, dotenv_values
import cfn_tools

from time import sleep
from contextlib import suppress
from collections import defaultdict

from botocore.exceptions import ClientError
import boto3
from boto3.s3.transfer import S3Transfer

import click

def get_env(name, default):
    return os.environ.get(name, default)

S3_DEV_BUCKET = get_env("S3_DEV_BUCKET", "flux-public-assets")
STACK_TMPL = "./stack/flux-securevote-voting-stack.yaml"

TEST_STACK_NAME = "sv-testnet-stack"
TEST_SUBDOMAIN = get_env("TEST_SUBDOMAIN", "tnalpha2")
TEST_NAMEPREFIX = "sv-testnet"
OFFSET = ""

VOTING_DOMAIN = get_env("VOTING_DOMAIN", "flux.vote")
MAXS_SSH_KEY = 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDCr1lcY0jTSmCARinvFJHelYGx2p+Ky0YxskSVj53ywYaLRN96w8WdN7rpCCosDQbd9KzvmKbBHHAlL8noEtARmxP4tKRvGGRyKawLLPm530CJRv4bSz03Iw2kz2V2fUWjA/RO2gNK9DCXTdDM67avv8oB/QvSobm1rSNKj6CcjTTJuQxGhJcXKrU/BZwugMIM3ELByyD6w8Jizm12JWGVgJTEIkgqgaNhmek2OLsw8+1hIC9EfhQunH9izzhEd2HoGYf3IJXlESnuRyhb7uOvOPysQDL8Hrt/Po6Wi3Lhlczy7q6wrlGQwO5/ORAfpYXGuk1lc3mTI/srgSgc38Vt'


def set_offset(offset):
    global TEST_STACK_NAME, TEST_NAMEPREFIX, TEST_SUBDOMAIN, OFFSET
    TEST_STACK_NAME += f'-{offset}'
    TEST_SUBDOMAIN += f'-{offset}'
    TEST_NAMEPREFIX += f'-{offset}'
    OFFSET = offset


cfn = None
SILENT = False


def echo(*args, sep: str = " ", **kwargs):
    if not SILENT:
        click.echo(sep.join(args), **kwargs)


def must_run(cmd, silent=False):
    logging.info("Running `%s`" % cmd)
    out = subprocess.STDOUT
    err = None
    if silent:
        out = subprocess.DEVNULL
        err = out
    if type(cmd) is list:
        to_run = cmd
    elif type(cmd) is str:
        to_run = cmd.split(' ')
    else:
        raise Exception("must_run only accepts str or list")
    exit_code = subprocess.check_call(to_run, stdout=out, stderr=err)
    logging.debug("Command `%s` exited w code %d" % (cmd, exit_code))
    if exit_code != 0:
        logging.error("Failed to run %s" % cmd)
        raise Exception("Failed to run required cmd: %s" % cmd)


class CmdRunner:
    def __init__(self, cmd_runner=must_run):
        self.cmds = []
        self.cmd_runner = cmd_runner

    def add(self, name, cmd):
        self.cmds.append((name, cmd))

    def run(self, cmd_runner=None):
        cmd_runner = self.cmd_runner if cmd_runner is None else cmd_runner
        for (n, cmd) in self.cmds:
            logging.info("Running ({name}) as cmd:\n\t{cmd}\n".format(name=n, cmd=cmd))
            cmd_runner(cmd)


def print_output(msg):
    print("\n### RESULT ###\n\n{}".format(msg))


def get_stack(stack_name):
    ss = list(filter(lambda s: s['StackName'] == stack_name, cfn.list_stacks()['StackSummaries']))
    if len(ss) > 0:
        return ss[0]
    return None


def get_stack_details(stack_name):
    ss = list(filter(lambda s: s['StackName'] == stack_name, cfn.describe_stacks(StackName=stack_name)['Stacks']))
    return None if len(ss) == 0 else ss[0]


def get_stack_resource(stack_name, logical_resource_name):
    return cfn.describe_stack_resource(StackName=stack_name, LogicalResourceId=logical_resource_name)['StackResourceDetail']


def is_in_prog(stack_name):
    s = get_stack(stack_name)
    return s and 'IN_PROGRESS' in s['StackStatus']


def stack_exists(stack_name):
    s = get_stack(stack_name)
    return s and s['StackStatus'] != 'DELETE_COMPLETE'


def stack_failed(stack_name):
    s = get_stack(stack_name)
    return s and ('FAILED' in s['StackStatus'] or 'ROLLBACK' in s['StackStatus'])


def await_in_prog(stack_name, heading_prefix="AWAITING", fullscreen=True):
    if is_in_prog(stack_name):
        logging.info("Waiting for CFN deploy to complete before we trigger another.")
        stream_cfn_events(stack_name, heading_prefix=heading_prefix, fullscreen=fullscreen)
        logging.info("Previous deploy completed, performing deploy...")


def delete_stack(stack_name):
    r = cfn.delete_stack(StackName=stack_name)
    while stack_exists(stack_name):
        time.sleep(0.1)
    return r


def stack_del_if_necessary(stack_name):
    if stack_exists(stack_name) and get_stack(stack_name)['StackStatus'] == 'ROLLBACK_COMPLETE':
        logging.warning("Deleting {} as it's in ROLLBACK_COMPLETE".format(stack_name))
        delete_stack(stack_name)


def create_stack(stack_name, obj_url, params_aws):
    extra = {} if params_aws is None else {'Parameters': params_aws}
    r = cfn.create_stack(
        StackName=stack_name,
        TemplateURL=obj_url,
        Capabilities=['CAPABILITY_NAMED_IAM', 'CAPABILITY_AUTO_EXPAND'],
        OnFailure="DELETE",
        TimeoutInMinutes=20,
        **extra
    )
    return r['StackId']


def update_stack(stack_name, obj_url, params_aws):
    extra = {} if params_aws is None else {'Parameters': params_aws}
    r = cfn.update_stack(
        StackName=stack_name,
        TemplateURL=obj_url,
        Capabilities=['CAPABILITY_NAMED_IAM', 'CAPABILITY_AUTO_EXPAND'],
        **extra
    )
    return r['StackId']


def create_or_update_stack(stack_name, obj_url, params):
    if stack_exists(stack_name):
        return update_stack(stack_name, obj_url, params)
    else:
        return create_stack(stack_name, obj_url, params)


def get_failed_msgs(stack_name):
    evts_after = get_stack(stack_name).get('LastUpdatedTime', None)

    try:
        evts = cfn.describe_stack_events(StackName=stack_name)['StackEvents']
    except:
        logging.warning("***** Failed to get stack events! *****")
        return []
    evts_notable = list(
        filter(lambda evt:
               ('FAILED' in evt['ResourceStatus'] or 'ROLLBACK_IN_PROGRESS' in evt['ResourceStatus']) and
               (evts_after is None or evt['Timestamp'] > evts_after), evts))
    evts_w_dupes = list([(evt['LogicalResourceId'], evt.get('ResourceStatusReason', evt)) for evt in evts_notable])
    resources_done = set()
    evts_final = []
    for (r_id, reason) in evts_w_dupes:
        if r_id not in resources_done:
            evts_final.append((r_id, reason))
            resources_done.add(r_id)
    return evts_final


def cfn_outputs_to_dict(outputs):
    return {d['OutputKey']: d['OutputValue'] for d in outputs}


def _cfn_stack_extract_resources_status(stack_name, recursive=False, update_start: datetime = None, parent=None, max_old=5):
    try:
        evts = cfn.describe_stack_events(StackName=stack_name)['StackEvents']
    except ClientError as e:
        if "does not exist" in str(e):
            return {}, [], update_start
        elif "(Throttling)" in str(e):
            sleep(0.3)
            return _cfn_stack_extract_resources_status(stack_name=stack_name, recursive=recursive,
                                                       update_start=update_start, parent=parent)
        else:
            raise e
    resources = {}
    _res_ord = []
    root = None

    # find update_start first
    if update_start is None:
        for evt in evts:
            r_name = evt['LogicalResourceId']
            is_update_create_complete = evt['ResourceStatus'] in ['UPDATE_IN_PROGRESS', 'CREATE_IN_PROGRESS',
                                                                  'UPDATE_COMPLETE', 'CREATE_COMPLETE']
            if update_start is None and r_name == stack_name and is_update_create_complete:
                # just break when we get to this point since we don't want anything afterwards.
                update_start = evt['Timestamp']
                break

    n_old_counter = 0
    for evt in evts:
        r_name = evt['LogicalResourceId']

        if r_name in resources or r_name in _res_ord:  # resources we already track
            continue

        if r_name == stack_name:
            if parent is None and root is None:
                root = r_name
            else:
                continue
        is_root = root == r_name
        is_stack = evt['ResourceType'] == "AWS::CloudFormation::Stack"
        is_old = update_start and evt['Timestamp'] < update_start
        t_plus_seconds = (evt['Timestamp'] - update_start).total_seconds()
        seconds_ago = (datetime.now(timezone.utc) - evt['Timestamp']).total_seconds()
        resources[r_name] = r = {'status': evt['ResourceStatus'],
                                 'ts': colors('dim_white')("   (old)") if is_old else f"{seconds_ago:>3.0f}s ago",
                                 'reason': evt.get('ResourceStatusReason', '<MISSING>'),
                                 'type': evt.get('ResourceType', ""),
                                 # we always want to show stacks, so they're never "old"
                                 'is_old': is_old,
                                 'parent': parent or "<Root>",
                                 'evt': evt,
                                 'depth': 0 if is_root else 1
                                 }
        # n_old = len(list(filter(lambda k: resources[k]['is_old'] and resources[k]['parent'] == stack_name, resources)))
        if is_stack or not r['is_old'] or n_old_counter < max_old:
            _res_ord.insert(0, r_name)
            n_old_counter += 1 if r['is_old'] and not is_stack else 0
        if recursive and is_stack and r_name != stack_name:
            phys_id = evt['PhysicalResourceId']
            if phys_id != "":
                sub_name = phys_id.split('/')[1]
                sub_res, sub_res_ord, _meh = _cfn_stack_extract_resources_status(
                    sub_name, recursive=recursive, update_start=update_start, parent=stack_name
                )
                _res_ord = [f"{r_name}/{n}" for n in sub_res_ord] + _res_ord
                resources.update({f"{r_name}/{k}": dict(v, depth=v['depth'] + 1) for k, v in sub_res.items()})

    root_list_maybe = [] if root is None else [root]
    used = set(root_list_maybe)
    res_ord = [r for r in _res_ord if r not in used and (used.add(r) or True)] + root_list_maybe

    return resources, res_ord, update_start


def get_c(cs, name: str) -> str:
    ns = name.split('_')
    color = ns[-1].upper()
    return (Style.DIM if 'dim' in ns else '') \
           + (Style.BRIGHT if 'l' in ns else '') \
           + cs.__getattribute__(ns[-1].upper()) if color else ''


def colors(fore='reset', back='reset', prefix='', suffix=''):
    def mk_colorful(msg):
        return f"{get_c(Fore, fore)}{get_c(Back, back)}{prefix}{msg}{suffix}{Fore.RESET}{Back.RESET}{Style.RESET_ALL}"
    return mk_colorful


def fmt_type(_r):
    tys = _r['type'].split('::')[1:]
    abbreviations = {
        'CloudFormation': 'CFN',
        'ApiGateway': 'ApiG',
        'Route53': 'R53'
    }
    return '::'.join([abbreviations.get(tys[0], tys[0])] + tys[1:])


def fmt_r(r, _r):
    rs = r.split('/')
    rs[-1] = colors('l_blue')(rs[-1])
    status_colors = {
        "DELETE_FAILED": colors('black', 'red'),
        "DELETE_IN_PROGRESS": colors('red', 'black'),
        "DELETE_COMPLETE": colors('l_red', 'black'),

        "CREATE_FAILED": colors('red'),
        "CREATE_IN_PROGRESS": colors('l_green'),
        "CREATE_COMPLETE": colors('dim_green'),

        "UPDATE_FAILED": colors('red'),
        "UPDATE_IN_PROGRESS": colors('l_green'),
        "UPDATE_COMPLETE": colors('dim_green'),

        "CLEANUP": colors('l_cyan'),
        "IS_OLD": colors('dim_white'),
    }
    s = _r['status']
    color_key = "IS_OLD" if _r['is_old'] else "CLEANUP" if "CLEANUP_IN_PROG" in s else s
    status = status_colors.get(color_key, colors())(_r['status'])
    return f"{status} - {'/'.join(rs)}"


def stream_cfn_events(stack_name, heading_prefix=None, skip_old=False, fullscreen=True):
    # echo(json.dumps(_cfn_stack_extract_resources_status(stack_name, recursive=True), indent=2))
    # return
    import curses

    _e = None

    term = Terminal()

    def clear_term():
        if fullscreen:
            print(term.clear())

    clear_term()

    def _run():
        nonlocal _e
        ansi_escape = re.compile(r'\x1B[@-_][0-?]*[ -/]*[@-~]')

        def true_len(msg: str):
            return len(ansi_escape.sub('', msg))

        def addstr(y, x, msg):
            if fullscreen:
                with term.location(x, y):
                    print(msg)
            else:
                print((x, y), msg)

        def gen_heading(update_start: datetime = None):
            dt = update_start or datetime.utcnow()
            heading = f'CFN Status ({stack_name})'
            if heading_prefix:
                heading = f'[{heading_prefix}] {heading}'
            return f'{dt.strftime("%H:%M:%S")} {heading}'

        def gen_progress_rotate(i):
            return {0: "|", 1: "/", 2: "—", 3: "\\"}[i % 4]

        addstr(0, 0, gen_heading())
        loop_counter = 0

        try:
            while is_in_prog(stack_name):
                loop_counter += 1
                try:
                    resources, _resources_order, _update_start = _cfn_stack_extract_resources_status(stack_name, recursive=True)
                except ClientError as e:
                    if 'does not exist' in str(e):
                        echo(f"ClientError: {str(e)}")
                        break
                    raise e
                clear_term()
                stdscr_height, stdscr_width = term.height, term.width
                addstr(0, 0, gen_heading(_update_start)) # + f" | update started: {_update_start.strftime('%H:%M:%S')}")
                l_num = 1
                # max_depth = max([s.count('/') for s in _resources_order])
                # last_depth = 0
                _rs_ord = _resources_order[::-1]
                _rs_with_neighbours = list(zip([None] + _rs_ord, _rs_ord, _rs_ord[1:] + [None]))
                # addstr(l_num, 0, f"{_rs_with_neighbours}")
                # l_num += 1
                for (prev_r, r, next_r) in _rs_with_neighbours:
                    if r not in resources:
                        addstr(l_num, 0, colors('red')(f"Not found: {r}"))
                        l_num += 1
                    else:
                        if l_num > stdscr_height - 2:
                            break

                        _r = resources[r]
                        _r_next = resources.get(next_r, None)
                        _r_prev = resources.get(prev_r, None)

                        if _r['is_old'] and skip_old:
                            continue

                        depth = _r['depth']
                        next_depth = _r_next['depth'] if _r_next else 0
                        prev_depth = _r_prev['depth'] if _r_prev else 0

                        start_char = "├" if prev_depth <= depth == next_depth or prev_depth > depth \
                            else "└" if next_depth == 0 \
                            else "└" if next_depth > depth \
                            else "└" if next_depth < depth \
                            else "┬"
                        end_char = "─" if "::Stack" not in _r['type'] \
                            else "┬" if prev_depth < depth \
                            else "├" if prev_depth == depth \
                            else "┬" if prev_depth > depth \
                            else "x"
                        # end_char = ("┬" if depth > 0 else "├") if "::Stack" in _r['type'] else " "
                        prefix = " " if _r['is_old'] else \
                            (gen_progress_rotate(loop_counter) if "IN_PROGRESS" in _r['status'] else "✔")
                        prefix += ("┆ " if depth > 1 else "") + "  " * (depth-2) + (f"{start_char}─" if depth > 0 else "")
                        prefix += end_char
                        # prefix += colors('red')(f"[{rs_left:>2d}]")

                        the_str = f"{_r['ts']} {prefix}─ {fmt_r(r, _r)}"
                        type_msg = fmt_type(_r)
                        total_len = true_len(the_str + type_msg) + 2
                        if total_len <= stdscr_width:
                            the_str = the_str + ' ' + colors('dim_cyan')("." * (stdscr_width - total_len))
                        else:
                            max_len = (stdscr_width - 2 - true_len(type_msg))
                            the_str = filter(lambda s: true_len(s) <= max_len, [the_str[:i] for i in range(len(the_str))][::-1]).__next__()
                            the_str += "…" + Fore.RESET + Back.RESET + Style.RESET_ALL
                        the_str += ' ' + colors('cyan')(fmt_type(_r))
                        addstr(l_num, 0, the_str)  # [:max_str_len]
                        if "FAILED" in _r['status']:
                            l_num += 1
                            addstr(l_num, 0, f"         {prefix} --> {_r['reason']}")  # [:max_str_len]
                        last_depth = depth
                        l_num += 1
                while l_num < stdscr_height - 1:
                    addstr(l_num, 0, " ")
                    l_num += 1
                time.sleep(2)

            addstr(1, 0, f"----------- STACK ({stack_name}) COMPLETED! ----------- In Progress: {is_in_prog(stack_name)}")
            time.sleep(1.5)
        except Exception as e:
            logging.error(f"Error in CFN stream: {e}, {repr(e)}")
            sys.stderr.write(f"Error in CFN stream: {e}, {repr(e)}\n")
            print_tb(e.__traceback__)
            with open('__tmp_manage_log', 'a') as f:
                f.write(f"Exception ({e}) at {time.time()} while streaming CFN events")
                f.write('\n\n'.join([str(time.time()), str(e), repr(e), '']))
            _e = e
            raise e

    if fullscreen:
        with term.fullscreen():
            _run()
    else:
        _run()

    if _e is not None:
        echo(f"Error in stream events: {_e}, {repr(_e)}")
        sys.stderr.write(f"Error in stream events: {_e}, {repr(_e)}")


def s3_upload(filepath, obj_key, public_read=True):
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)
    extra_args = {'ACL': 'public-read'} if public_read else {}
    s3_tfer.upload_file(filepath, S3_DEV_BUCKET, obj_key, extra_args=extra_args)
    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, S3_DEV_BUCKET, obj_key)
    return obj_url


def dict_to_cfn_params(params):
    return [{'ParameterKey': k, 'ParameterValue': v} for k, v in params.items()]


def is_wsl():
    return os.path.exists('/bin/wslpath')


def docker_lambda(cmd, extra_args=''):
    wsl = is_wsl()
    if wsl:
        print("Detected WSL...")
    mnt_dir = '$PWD' if not wsl else '$(wslpath -w $PWD)'
    # sts = boto3.client('sts')
    # session_token = sts.get_session_token(DurationSeconds=900)['Credentials']
    # env_args = ' '.join([f"-e {k}={v}" for k,v in {
    #     'AWS_ACCESS_KEY_ID': session_token['AccessKeyId'],
    #     'AWS_SESSION_TOKEN': session_token['SessionToken'],
    #     'AWS_SECRET_ACCESS_KEY': session_token['SecretAccessKey'],
    # }.items()])
    env_args = ''
    return os.system(f'docker run --rm -t -v "{mnt_dir}":/var/task {env_args} {extra_args} lambci/lambda:build-python3.6 {cmd}')


@click.group()
@click.option("--debug/--no-debug", default=False)
@click.option("--offset", "-o", default="", type=click.STRING, help="use an offset for names to avoid conflicts.")
@click.option("--region", default="", type=click.STRING, help="specify an AWS region if need be")
def cli(debug, offset, region):
    global cfn
    if debug:
        logging.basicConfig(level=logging.DEBUG)
        logging.debug("Debug mode enabled")
    if offset:
        set_offset(offset)
    cfn_extras = {} if region == '' else {'region_name': region}
    cfn = boto3.client('cloudformation', **cfn_extras)


py_targets_raw = ["cr", "members"]
py_targets = click.Choice(py_targets_raw + ['all'])


@cli.command(name='pip')
@click.argument('target', default="all", type=py_targets) #, help="The target python app to install deps for; with 'all' being all targets")
@click.argument('pkgs', nargs=-1)
@click.option('--no-system', type=click.BOOL, is_flag=True, default=False,
              help="do not include --system in pip install args")
@click.option('--pip-args', type=click.STRING, default='', help="extra args to pass to pip3 install")
@click.option('--use-docker', type=click.BOOL, is_flag=True, default=False,
              help="use the lambda-build docker container to install dependencies (required on MacOS and Windows")
def pip(target, pkgs, no_system, pip_args, use_docker):
    targets = py_targets_raw if target == "all" else [target]
    _pkgs = list(pkgs)
    target_paths = [{'cr': 'stack/cr/common', 'members': 'stack/app/members'}[target] for target in targets]
    for target_path in target_paths:
        _pip(target_path, _pkgs, no_system, pip_args, use_docker)


def _pip(target_path, pkgs, no_system, pip_args, use_docker):
    curr_dir = os.getcwd()
    if os.path.exists(target_path):
        reqs_file = 'requirements.txt'
        os.chdir(target_path)
        try:
            with open(reqs_file, 'r') as f:
                reqs_old = f.read().split('\n')
        except FileNotFoundError as e:
            reqs_old = []
        reqs = list(reqs_old)
        for pkg in pkgs:
            if pkg in reqs_old:
                continue
            reqs.append(pkg)
        print('New requirements file lines:', reqs)
        with open(reqs_file, 'w+') as f:
            f.write('\n'.join(reqs))
        print('Platform:', platform.system())
        system = '' if no_system else '--system'
        _cmd_outer = '{}'
        if platform.system() == "Darwin":
            _cmd_outer = 'docker run --rm -v "$PWD":/var/task lambci/lambda:build-python3.6 {}'
            system = ''
        # _cmd = _cmd_outer.format(...origcmd here...)
        pip_cmd = f'pip3 install --target=deps -r {reqs_file} --upgrade {pip_args}'
        # _ec = docker_lambda(pip_cmd)
        _ec = os.system(pip_cmd)

        if _ec != 0:
           raise Exception("Failed to install packages")
        print_output(f"Installed packages {pkgs} / {reqs} to {target_path}")
    else:
        raise Exception("Target of {} is unknown".format(target_path))
    os.chdir(curr_dir)


@cli.command(name='test-chaincode')
def test_chaincode():
    test_cmd = 'bash -c "cd stack/cr/chaincode; ls -al && tail cfnwrapper.py && tail lib.py; python3 test/test_mk_contract.py"'
    docker_lambda(test_cmd)


@cli.command(name="stream-cfn")
@click.argument('stack-name', type=click.STRING, default='')
def cmd_stream_cfn(stack_name):
    if stack_name == '':
        stack_name = TEST_STACK_NAME
    stream_cfn_events(stack_name)


@cli.command(name='upload-func')
@click.argument('func-path')
@click.argument('func-name')
def upload_func(func_path, func_name):
    if func_path[-3:] != ".py":
        logging.error("Must target a python file to upload (whole dir gets uploaded tho)")
        sys.exit(1)
    root_dir = os.path.dirname(os.path.realpath(__file__))
    dir_path = os.path.dirname(func_path)
    os.chdir(dir_path)
    if os.path.exists(f"{root_dir}/tmp-func.zip"):
        must_run(f'rm -v {root_dir}/tmp-func.zip', silent=True)
    must_run(f'zip -r {root_dir}/tmp-func.zip ./', silent=True)
    os.chdir(root_dir)
    with open('./tmp-func.zip', 'rb') as f:
        zip_bytes = f.read()
    # obj_key = f'./tmp-func-{int(time.time())}.zip'
    # obj_url = s3_upload(obj_key, hashlib.sha256(zip_bytes).hexdigest() + ".zip")

    awslam = boto3.client('lambda')
    awslam.update_function_code(FunctionName=func_name, ZipFile=zip_bytes, Publish=True)

    print_output(f"Updated function {func_name}")


@cli.command(name='deploy-ns')
@click.argument('stack-path')
@click.argument('stack-name')
@click.option('--params', default='',
              help="(JSON Dict) Parameters to use. Default will use '{\"pOffset\": \"<value provided via --offset>\"}'")
def deploy_nestedstack(stack_path, stack_name, params):
    TMP_TMPL_FILE = "./tmp-nestedstack-dev.yaml"
    pkg_cmd = f"aws cloudformation package --template-file {stack_path} --s3-bucket {S3_DEV_BUCKET} --output-template-file {TMP_TMPL_FILE}"
    must_run(pkg_cmd, silent=True)

    filename = os.path.basename(stack_path)
    obj_key = f'./ns-dev/tmp-{int(time.time())}-{filename}'
    obj_url = s3_upload(TMP_TMPL_FILE, obj_key)

    if not params:
        prev_params = cfn.describe_stacks(StackName=stack_name)['Stacks'][0]['Parameters']
        cfn_params = [{'ParameterKey': p['ParameterKey'], 'UsePreviousValue': True} for p in prev_params]
        print(f"Using params: {json.dumps(cfn_params)}")
    else:
        json_params = json.loads(params)
        if type(json_params) is list:
            cfn_params = json_params
        else:
            cfn_params = dict_to_cfn_params(json_params if params else {'pOffset': OFFSET})
    sid = create_or_update_stack(stack_name, obj_url, cfn_params)
    logging.info(f"Stack SID: {sid}")

    stream_cfn_events(stack_name, heading_prefix="DEPLOY-NS-DEV")
    print_output(f"Stack deploy/create/update run for {stack_name} w sid: {sid}")

    if stack_failed(stack_name):
        msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
        print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))


@cli.command(name='deploy-macros')
@click.argument('stack-name', default='sv-macros')
def deploy_macros(stack_name):
    TMP_TMPL_FILE = "tmp-macros.yaml"

    pkg_cmd = f"aws cloudformation package --template-file ./stack/sv-macros.yaml --s3-bucket {S3_DEV_BUCKET} --output-template-file {TMP_TMPL_FILE}"
    print("Package:", pkg_cmd)
    must_run(pkg_cmd, silent=True)

    obj_key = "sv-macros.yaml"
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)
    s3_tfer.upload_file(TMP_TMPL_FILE, S3_DEV_BUCKET, obj_key, extra_args={'ACL': 'public-read'})
    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, S3_DEV_BUCKET, obj_key)

    params_aws = []

    if stack_exists(stack_name):
        sid = update_stack(stack_name, obj_url, params_aws)
    else:
        sid = create_stack(stack_name, obj_url, params_aws)

    stream_cfn_events(stack_name, heading_prefix="DEPLOY")


@cli.command(name='destroy')
@click.argument('stack-name', type=click.STRING, default='')
@click.option("--watch", default=False, type=click.BOOL, is_flag=True, help="Stream CFN events as it deploys.")
@click.pass_context
def destroy(ctx, watch, stack_name):
    if stack_name == '':
        stack_name = TEST_STACK_NAME

    if watch:
        stream_cfn_events(stack_name, heading_prefix="AWAIT")

    del_resp = cfn.delete_stack(StackName=stack_name)
    print(f"Del response: {del_resp}")

    if watch:
        stream_cfn_events(stack_name, heading_prefix="DELETE")

    print_output(f"Deleted: {del_resp}")


def _step_to_parameters(step: int):
    steps = [ {'pCreateNodes': 'false'}, {'pCreateChaincodeStack': 'false'}, {'pCreateMembersApp': 'false'}, {} ]
    return steps[step]


@cli.command(name='deploy')
@click.argument('stack-name', type=click.STRING, default='')
@click.option("--deploy/--no-deploy", default=True, is_flag=True)
@click.option("--open-browser/--no-open-browser", default=False, is_flag=True)
@click.option("--del-packaged-tmpl/--no-del-packaged-tmpl", default=True, is_flag=True,
              help="Remove tmp-stack.yaml after we're done generating + uploading it")
@click.option("--watch", default=False, type=click.BOOL, is_flag=True, help="Stream CFN events as it deploys.")
@click.option("--ssh-key", default=MAXS_SSH_KEY, type=click.STRING,
              help="the ssh key with which to configure EC2 nodes.")
@click.option("--use-existing", default=False, is_flag=True, type=click.BOOL,
              help="use tmp-stack.yaml if it exists instead of running aws cfn package")
@click.option("--use-last-uploaded", default=False, is_flag=True, type=click.BOOL,
              help="do not package a new template, just redeploy the last one uploaded to S3.")
@click.option("--step", default=3, type=click.IntRange(0, 3), help="Proceed only to step N of the stack deployment. The stack will _progressively_ deploy more and more resources as you increase step. The default is to deploy everything.")
@click.pass_context
def deploy(ctx, stack_name, deploy, open_browser, del_packaged_tmpl, watch, ssh_key, use_existing,
                use_last_uploaded, step):
    if stack_name == '':
        stack_name = TEST_STACK_NAME

    if deploy:
        await_in_prog(stack_name)

    TMP_TMPL_FILE = 'tmp-stack.yaml'
    obj_key = "templates/" + STACK_TMPL.split('/')[-1]
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)

    if not use_last_uploaded:
        if os.path.exists(TMP_TMPL_FILE) and use_existing:
            print(f"{TMP_TMPL_FILE} exists - skipping `aws cloudformation package`; "
                  f"use --disable-use-existing to disable this and rm the old tmp file.")
        else:
            must_run("aws cloudformation package --template-file {} --s3-bucket {} --output-template-file {}"
                     .format(STACK_TMPL, S3_DEV_BUCKET, TMP_TMPL_FILE), silent=True)
        # upload tmp file regardless
        s3_tfer.upload_file(TMP_TMPL_FILE, S3_DEV_BUCKET, obj_key, extra_args={'ACL': 'public-read'})

    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, S3_DEV_BUCKET, obj_key)
    print(f"Template URL: {obj_url}")

    params = {
        'NamePrefix': TEST_NAMEPREFIX,
        # 'HostedZone': 'Z2NVOFJHPZ9S2O',
        'HostedZoneDomain': VOTING_DOMAIN,
        'EC2InstanceType': 't2.small',
        'NumberOfEthereumConsensusNodes': '1',
        'NumberOfEthereumPublicNodes': '1',
        'Subdomain': TEST_SUBDOMAIN,
        'SSHKey': ssh_key,
        'AdminEmail': 'test-stack-flux-vote@xk.io',
        'pDeployMacros': 'false',
        # 'pDeployAcmAutovalidate': 'false',
        # 'Nonce': str(int(time.time()))
    }
    params.update(**_step_to_parameters(step))
    params_aws = dict_to_cfn_params(params)

    cfn_console_create_url = "https://console.aws.amazon.com/cloudformation/home?region={region}#/stacks/new?stackName={stack_name}&templateURL={tmpl_url}".format(
        obj_url, region=s3.meta.region_name, stack_name=stack_name, tmpl_url=urllib.parse.quote(obj_url, safe=''))

    def gen_cfn_evt_url(sid):
        return "https://ap-southeast-2.console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/{}/events".format(
            urllib.parse.quote(sid, safe=''))

    def gen_open_url_cmd(url):
        return "cmd.exe /c start {}".format(url)

    if deploy:
        await_in_prog(stack_name)
        stack_del_if_necessary(stack_name)
        if stack_exists(stack_name):
            sid = update_stack(stack_name, obj_url, params_aws)
        else:
            sid = create_stack(stack_name, obj_url, params_aws)
        cfn_evt_url = gen_cfn_evt_url(sid)
        if open_browser:
            os.system(gen_open_url_cmd(cfn_evt_url))
        if watch:
            stream_cfn_events(stack_name, heading_prefix="DEPLOY")
            _exists = stack_exists(stack_name)
            if not _exists or stack_failed(stack_name):
                if _exists:
                    msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
                    print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))
                else:
                    print_output("Deploy failed and is deleted.")
            else:
                print_output("Deploy Success! {}".format(cfn_evt_url))
                if del_packaged_tmpl:
                    os.system("rm {}".format(TMP_TMPL_FILE))
                deets = get_stack_details(stack_name)

                print_output(f"Outputs: {json.dumps(cfn_outputs_to_dict(deets['Outputs']), indent=2)}")
        else:
            print_output("Initiated deploy of {}\n\nLink: {}".format(sid, cfn_evt_url))
            if del_packaged_tmpl:
                os.system("rm {}".format(TMP_TMPL_FILE))

    else:
        if open_browser:
            _to_run = gen_open_url_cmd(cfn_console_create_url)
            print("Opening CFN template via console. CMD: {}".format(_to_run))
            os.system(_to_run)
        print_output("""Uploaded {}
        Launch via CloudFormation: {}""".format(obj_url, cfn_console_create_url))


def get_ns_details(sn, r_name):
    for r in state.get_stack_resources(sn):
        if not (r['LogicalResourceId'] == r_name and r['ResourceType'] == "AWS::CloudFormation::Stack"):
            break
        ns_arn = r['PhysicalResourceId']
    else:
        raise Exception(f"Cannot find nested stack with name {r_name} in main stack {sn}")
    with open(STACK_TMPL, 'r') as f:
        contents = f.read()
        results = re.search(f"{r_name}:[\n\s]*Type: AWS::CloudFormation::Stack[\n\s\w:]*TemplateURL:(.*)\.yaml", contents, re.M | re.S)
        ns_file_path = results.group(1) + ".yaml"
    return { 'arn': ns_arn, 'file_path': os.path.join('./stack', ns_file_path) }


def default_params_from_env(env_name, evs):
    params = {
        'NamePrefix': evs.NAME_PREFIX,
        'HostedZoneDomain': evs.DOMAIN,
        'EC2InstanceType': 't2.small',
        'NumberOfEthereumConsensusNodes': '1',
        'NumberOfEthereumPublicNodes': '1',
        'Subdomain': evs.SUBDOMAIN,
        'AdminEmail': evs.get('EMAIL_FROM_ADDR', 'test-stack-flux-vote@xk.io'),
        'pDeployMacros': 'false',
        # 'pDeployAcmAutovalidate': 'false',
        # 'Nonce': str(int(time.time()))
    }
    params.update({ 'SSHKey': evs.get("SSH_KEY", MAXS_SSH_KEY)})  #  if env_name != "prod" else ''

    return params


def gen_packaged_stack_tmp_filename(env_name):
    return f'tmp-stack.{env_name}.yaml'


def get_evs(env_name):
    env_file = f'.env.{env_name}'
    load_dotenv(env_file, override=True)
    evs = AttrDict(dotenv_values(env_file))
    return evs


@cli.command(name='sync-env')
@click.argument('env-name', type=click.STRING, default='dev')
@click.option("--nested-stack", "-ns", type=click.STRING, help="The resource name of the nested stack to update")
@click.option("--watch/--no-watch", default=True, is_flag=True, help="Stream CFN events as it deploys.")
@click.option("--set-params", type=click.STRING, help="JSON encoded parameters. New values will be set these params, and existing values will be removed from the cache.")
@click.option("--update-params", type=click.STRING, help="JSON encoded parameters. New values will be set _only_ on these params, and existing values will be used for existing params.")
@click.option("--pkg-python/--no-pkg-python", default=True)
@click.option("--use-last-uploaded", default=False, is_flag=True,
              help="do not package a new template, just redeploy the last one uploaded to S3.")
@click.option("--no-fullscreen", default=False, is_flag=True)
@click.pass_context
def sync_env(ctx, env_name, nested_stack, watch, set_params, update_params, pkg_python, use_last_uploaded, no_fullscreen):
    if set_params and update_params:
        raise Exception("Cannot set and update params at the same time. Use one.")
    fullscreen = not no_fullscreen

    env_name = env_name if not env_name[:5] == ".env." else env_name[5:]

    evs = get_evs(env_name)
    stack_name = evs.STACK_NAME

    if deploy:
        await_in_prog(stack_name, fullscreen=fullscreen)

    tmp_template_filename = gen_packaged_stack_tmp_filename(env_name)
    obj_key = f"templates/{env_name}" + os.path.split(evs.STACK_TEMPLATE)[-1]
    s3 = boto3.client('s3')
    s3_tfer = S3Transfer(s3)

    if not use_last_uploaded:
        must_run("aws cloudformation package --template-file {} --s3-bucket {} --output-template-file {}"
                 .format(evs.STACK_TEMPLATE, evs.S3_CFN_SUPPORT_BUCKET, tmp_template_filename), silent=True)
        s3_tfer.upload_file(tmp_template_filename, evs.S3_CFN_SUPPORT_BUCKET, obj_key, extra_args={'ACL': 'public-read'})

    obj_url = "{}/{}/{}".format(s3.meta.endpoint_url, evs.S3_CFN_SUPPORT_BUCKET, obj_key)
    print(f"Template URL: {obj_url}")

    params = default_params_from_env(env_name, evs)
    # params.update(**_step_to_parameters(step))
    params_aws = dict_to_cfn_params(params)

    cfn_console_create_url = "https://console.aws.amazon.com/cloudformation/home?region={region}#/stacks/new?stackName={stack_name}&templateURL={tmpl_url}".format(
        obj_url, region=s3.meta.region_name, stack_name=stack_name, tmpl_url=urllib.parse.quote(obj_url, safe=''))

    print_output("""Uploaded {}
            Launch via CloudFormation: {}""".format(obj_url, cfn_console_create_url))

    def gen_cfn_evt_url(sid):
        return "https://ap-southeast-2.console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/{}/events".format(
            urllib.parse.quote(sid, safe=''))

    def gen_open_url_cmd(url):
        return "cmd.exe /c start {}".format(url)

    await_in_prog(stack_name, heading_prefix="AWAITING [UNEXPECTED]", fullscreen=fullscreen)
    stack_del_if_necessary(stack_name)
    if stack_exists(stack_name):
        sid = update_stack(stack_name, obj_url, params_aws)
    else:
        sid = create_stack(stack_name, obj_url, params_aws)
    cfn_evt_url = gen_cfn_evt_url(sid)
    if watch:
        stream_cfn_events(stack_name, heading_prefix="DEPLOY", fullscreen=fullscreen)
        _exists = stack_exists(stack_name)
        if not _exists or stack_failed(stack_name):
            if _exists:
                msgs = ["{}: {}".format(a, b) for (a, b) in get_failed_msgs(stack_name)]
                print_output("Deploy failed. Msgs: \n\n{}".format('\n'.join(msgs)))
            else:
                print_output("Deploy failed and is deleted.")
        else:
            print_output("Deploy Success! {}".format(cfn_evt_url))
            deets = get_stack_details(stack_name)

            print_output(f"Outputs: {json.dumps(cfn_outputs_to_dict(deets['Outputs']), indent=2)}")
    else:
        print_output("Initiated deploy of {}\n\nLink: {}".format(sid, cfn_evt_url))


lambdas = {
    '': ''
}


def package_lambda(resource_name: str, lambda_path: str, layers: List[Path]):
    # todo: maybe should use working directory?
    root_dir = Path(os.path.dirname(os.path.realpath(__file__)))
    tmp_zip = f"{root_dir}/tmp-func-{resource_name}.zip"

    if os.path.exists(tmp_zip):
        must_run(f'rm -v {tmp_zip}', silent=True)

    os.chdir(lambda_path)
    must_run(f'zip -r {tmp_zip} ./', silent=True)

    for layer in layers:
        os.chdir(layer.parent)
        must_run(f'zip -ur {tmp_zip} ./{layer.name}', silent=True)
    os.chdir(root_dir)
    return tmp_zip


@cli.command(name='sync-lambda')
@click.argument('env-name', type=click.STRING, default='dev')
@click.argument('resource-name')
@click.argument('nested', nargs=-1)
def upload_func(env_name, resource_name, nested):
    evs = get_evs(env_name)
    root_tmpl_path = Path(evs.STACK_TEMPLATE).resolve()
    tmpls = [ (root_tmpl_path.parent, evs.STACK_NAME, cfn_tools.load_yaml(root_tmpl_path.read_text())) ]

    for ns_logical_name in nested:
        (last_path, last_name, last_stack) = tmpls[-1]
        ns_resource = last_stack['Resources'][ns_logical_name]
        ns_path = last_path / Path(ns_resource['Properties']['TemplateURL'])
        ns_stack_name = get_stack_resource(last_name, ns_logical_name)['PhysicalResourceId'].split('/')[-2]
        tmpls.append((ns_path.parent, ns_stack_name, cfn_tools.load_yaml(ns_path)))

    final_tmpl_dir, final_stack_name, final_tmpl = tmpls[-1]
    lambda_func_name = get_stack_resource(final_stack_name, resource_name)['PhysicalResourceId']

    lambda_res = final_tmpl['Resources'][resource_name]['Properties']
    lambda_code_uri = lambda_res['CodeUri']
    lambda_path = final_tmpl_dir / lambda_code_uri

    print(lambda_path, lambda_code_uri, lambda_res)

    layers = [] if 'Layers' not in lambda_res else [ final_tmpl_dir / final_tmpl['Resources'][l['Ref']]['Properties']['ContentUri'] for l in lambda_res['Layers'] ]
    tmp_zip = package_lambda(resource_name, lambda_path, layers)

    with open(f'./{tmp_zip}', 'rb') as f:
        zip_bytes = f.read()
    # obj_key = f'./tmp-func-{int(time.time())}.zip'
    # obj_url = s3_upload(obj_key, hashlib.sha256(zip_bytes).hexdigest() + ".zip")

    awslam = boto3.client('lambda')
    resp = awslam.update_function_code(FunctionName=lambda_func_name, ZipFile=zip_bytes,
                                       S3Bucket=evs.S3_CFN_SUPPORT_BUCKET, Publish=True)

    print_output(f"Updated function {lambda_func_name}. Resp: {resp}")


# monkey patch so usage output looks nicer
sys.argv[0] = './manage'
cli()
